% !TeX spellcheck = en_US
\chapter{Introduction}\label{ch:introduction}

\section{Motivation}
The majority of data on the Internet is unstructured because it is mainly text. That makes it difficult for machines to extract knowledge from the data and answer specific queries. In the context of the Semantic Web, an attempt is made to build a knowledge base using structured data. Here the data is stored as graphs. A graph is an often used data structure which consists of nodes and edges. The edges connect the different nodes. This thesis will focus on knowledge graphs, which are about expressing knowledge or facts. A possible format for the such graphs is the Resource Description Framework (RDF)\footnote{\label{foot:2}https://www.w3.org/RDF/}, in which a graph is represented by triples of the form $ (subject, predicate, object) $, where $ subject $ and $object$ are nodes and $predicate$ is an edge of the graph. A triple is typically used to express a certain fact. \todo{hier noch genauer, was die einzelnen Komponenten sind}

In reality, such knowledge graphs can become very large with millions or even billions of nodes and edges. \todo{hier evtl Beispiele von knowledge bases} The following three use cases can then become very slow or even infeasible: storage, transmission and processing. Therefore we are looking for a method to compress knowledge graphs. 

The current most popular compressor for RDF data is HDT~\cite{hdt}. Here the data is made smaller by a compact representation of the triples. HDT is explained in more detail in chapter ~\ref{related_work_hdt}.

The task of this thesis is to compare HDT with a grammar-based compression. As the name suggests, such a compression is based on the principle of a formal grammar, with productions that can be nested among each other. There are not yet many grammar-based compression algorithms for graphs. One of the best known is GraphRePair~\cite{maneth}. This is a compressor that works for any type of graph and is therefore also applicable for RDF. Why the algorithm is particularly suitable for RDF is explained in chapter~\ref{related_work_grammar_based}.

It will be examined for which use cases which of the two approaches is more suitable. What these use cases are is explained in more detail below.



\section{General Idea}

%We will first explain roughly how grammar-based compression works. The details of the algorithm are explained in detail in chapter~\ref{ch:related_work}.
%
%A compression algorithm in general tries to find patterns in data that occur multiple times. Since we are interested in graphs here, these patterns consist of nodes and edges (and their labels). A grammar-based algorithm works as follows: 
%
%\begin{enumerate}
%	\item Search for a pattern $p$ occurring most often.  (Terminate if there is no pattern $p$ occurring more than once.)
%	\item Replace all occurrences of $p$ with a non-terminal $N_p$, store $p$ only at one place and let $N_p$ reference to $p$.
%	\item Go to step 1.
%\end{enumerate}
%
%In this way, the graph becomes smaller as you remove more redundancy. At the same time, no information is lost because the non-terminals are references the original data. The compression can therefore be completely reversed if that is desired. Also, querying is possible on the compressed graph since all information is still contained in it.

As already mentioned, there are essentially three use cases for RDF data:

\begin{enumerate}
	\item Storage
	\item Transmission
	\item Processing/Consumption
\end{enumerate}

The idea is that you can make all these use cases easier / possible by compression, especially if you are dealing with very large amounts of data. In the first two use cases, compression can be helpful by reducing the size of the data. Thus the data can be stored more compactly and above all can be transferred faster, which occurs frequently in reality and can become a problem due to possibly slow transfer speeds \todo{here possibly concrete numbers}.

The third use case (Processing/Consumption) is about reading or writing access to data. The more common case of read access is typically the execution of queries on RDF data. For example, you want to find out which other nodes a given node is connected to. But there are other examples which will be explained in the course of the thesis. A compression algorithm can help in this respect by making it possible to answer such queries directly on the compressed graphs. This may even be faster than on the original data due to the reduced size.

The aim of the thesis is to compare the two compressors (HDT and GRP) with regard to these use cases and finally determine which approach works better for which use cases.



\section{Thesis Structure}
\todo{machen}
